---
layout: ../../layouts/Layout.astro
title: HΩ
---

<div class="hero">

# HΩ

<div class="purpose-statement">Le progrès de la sûreté de l'IA<br/><span class="purpose-detail">par la collaboration, la recherche et l'éducation.</span></div>

<p class="mission-statement">Pour réduire les risques de l'IA, pour l'épanouissement de la vie consciente.</p>

<div class="cta-group">
  <a href="#impliquez-vous" class="btn btn-primary">Impliquez-vous</a>
</div>

</div>

<section id="ce-quon-fait">

## Ce que nous faisons

<div class="card-grid">

<div class="card">
  <div class="card-header">
    <h3>Séminaires IA garantie sécuritaire</h3>
    <span class="card-meta">Depuis 2024</span>
  </div>
  <p>Séminaires techniques mensuels sur les approches quantitatives et garanties de sûreté. Nous recevons des chercheurs de premier plan dont Yoshua Bengio, Steve Omohundro, Tan Zhi Xuan et Jobst Heitzig.</p>
  <div class="card-stats">
    <span>275+ abonnés</span>
  </div>
  <a href="https://luma.com/guaranteedsafeaiseminars" class="card-link">Calendrier →</a>
</div>

<div class="card">
  <div class="card-header">
    <h3>Sûreté de l'IA à Montréal</h3>
    <span class="card-meta">Depuis 2025</span>
  </div>
  <p>Hub local qui sert la communauté montréalaise en sûreté, éthique et gouvernance de l'IA. Meetups, sessions de cotravail, ateliers ciblés, accompagnement et collaborations.</p>
  <div class="card-stats">
    <span>1600+ membres</span>
  </div>
  <a href="https://aisafetymontreal.org" class="card-link">Visitez le site →</a>
</div>

<div class="card">
  <div class="card-header">
    <h3>Coordination canadienne en sûreté de l'IA</h3>
    <span class="card-meta">Depuis 2025</span>
  </div>
  <p>Groupe de coordination entre organisations canadiennes et réseau travaillant vers la sûreté de l'IA.</p>
  <a href="mailto:team@horizonomega.org?subject=Traité%20canadien%20sûreté%20IA" class="card-link">Contactez-nous →</a>
</div>

<div class="card">
  <div class="card-header">
    <h3>AI Safety Unconference</h3>
    <span class="card-meta">2018–2022, 2024</span>
  </div>
  <p>Événements dirigés par les participants avec présentations, sessions, discussions modérées et rencontres individuelles. Nous avons organisé AI Safety Unconference @ NeurIPS (2018–2022) et Virtual AI Safety Unconference (2024).</p>
  <div class="card-stats">
    <span>400+ chercheurs rassemblés</span>
  </div>
  <a href="https://www.horizonevents.info/" class="card-link">En savoir plus →</a>
</div>

<div class="card">
  <div class="card-header">
    <h3>Horizon Events</h3>
    <span class="card-meta">Depuis 2024</span>
  </div>
  <p>Nous organisons plusieurs séries d'événements mondiaux en sûreté de l'IA. Nous soutenons l'écosystème élargi d'événements et d'initiatives en sûreté de l'IA.</p>
  <a href="https://www.horizonevents.info/" class="card-link">Visitez le site →</a>
</div>

<div class="card">
  <div class="card-header">
    <h3>Proposez une collaboration</h3>
    <span class="card-meta">Ouvert</span>
  </div>
  <p>Vous avez une idée de projet collaboratif? Nous nous intéressons aux initiatives conjointes, aux partenariats de recherche, à la coorganisation d'événements et à la coordination inter-organisationnelle en sûreté de l'IA.</p>
  <a href="mailto:team@horizonomega.org?subject=Proposition%20de%20projet%20collaboratif" class="card-link">Proposez un projet →</a>
</div>

</div>

</section>

<section id="bilan">

## Bilan

Nous avons mobilisé des milliers de participants à travers nos événements et canaux depuis 2018. Nous avons établi une communauté de 1600+ membres à Montréal et facilité la collaboration inter-organisationnelle à l'échelle mondiale.

**[AI Safety Unconference @ NeurIPS](https://www.horizonevents.info/events/ai-safety-unconference) (2018–2022).** Années de rassemblements dirigés par les participants avec présentations éclair, discussions modérées et sessions individuelles. 60+ participants par événement provenant d'organismes de premier plan dont Anthropic, DeepMind, OpenAI, Mila, MIRI, MIT, Stanford, Oxford, Cambridge et plus.

**[Séminaires IA garantie sécuritaire](https://luma.com/guaranteedsafeaiseminars) (2024–présent).** Présentations techniques mensuelles avec 15–30 participants en direct par session, et 600+ inscriptions totales annuellement. Conférenciers invités : Yoshua Bengio, Steve Omohundro, Tan Zhi Xuan et Jobst Heitzig.

**[Communauté sûreté de l'IA de Montréal](https://aisafetymontreal.org/) (2025–présent).** Nous avons bâti l'écosystème local par des meetups, des sessions de cotravail, des ateliers ciblés et la coanimation du groupe de lecture en sûreté de l'IA de Mila (sessions bihebdomadaires avec 10–20 chercheurs). Nous servons des membres en sûreté, éthique et gouvernance de l'IA.

**[Atelier Limits to Control](http://limitstocontrol.org).** Coorganisation d'un atelier centré sur les difficultés ou impossibilités de contrôler des systèmes d'IA avancés.

**[Infolettre AI Safety Events & Training](https://aisafetyeventsandtraining.substack.com/).** Nous avons fondé son Substack en 2023, contribuant à la curation d'événements et à la croissance de la communauté.

<details>
  <summary>Ce que disent les participants</summary>
  <blockquote>« Utile pour suivre les avancées et lancer des collaborations. » — Haydn Belfield</blockquote>
  <blockquote>« Très utile pour rencontrer et discuter avec les chercheurs en sûreté de l'IA à NeurIPS. » — Esben Kran</blockquote>
  <blockquote>« Une excellente façon de rencontrer les meilleures personnes du domaine et propulser des idées audacieuses. » — Stuart Armstrong</blockquote>
  <blockquote>« Les petits groupes de discussion m'ont exposé à de nouvelles perspectives. » — Adam Gleave</blockquote>
</details>

</section>

<section id="impliquez-vous">

## Impliquez-vous

<div class="card-grid">

<div class="card">
  <h3>Bénévolat</h3>
  <p>Nous accueillons des bénévoles pour les opérations des séminaires, les synthèses de recherche, la sollicitation de conférenciers et le montage vidéo. Formation et gabarits fournis.</p>
  <a href="mailto:team@horizonomega.org?subject=Bénévolat" class="card-link">Contactez-nous →</a>
</div>

<div class="card">
  <h3>Partenariat</h3>
  <p>Nous collaborons avec des universités, des labos, des ONG et des organismes de normalisation pour coorganiser des sessions, partager des conférenciers et bâtir des projets pilotes.</p>
  <a href="mailto:team@horizonomega.org?subject=Partenariat" class="card-link">Contactez-nous →</a>
</div>

<div class="card">
  <h3>Soutien</h3>
  <p>Votre soutien nous permet d'élargir nos collaborations, événements et recherches. Commandites, subventions et contributions en nature (hébergement de lieu, sous-titrage, montage, design) bienvenues.</p>
  <a href="mailto:team@horizonomega.org?subject=Soutien" class="card-link">Contactez-nous →</a>
</div>

<div class="card">
  <h3>Conseillers</h3>
  <p>Nous cherchons des conseillers séniors en vérification, évaluations et gouvernance. Politique de conflit d'intérêts applicable.</p>
  <a href="mailto:team@horizonomega.org?subject=Conseillers" class="card-link">Contactez-nous →</a>
</div>

<div class="card">
  <h3>Suivi</h3>
  <p>Restez au courant des événements en sûreté de l'IA, des opportunités de formation et de nos dernières initiatives. Abonnez-vous à notre infolettre et suivez-nous sur les réseaux sociaux.</p>
  <a href="https://horizonomega.substack.com/" class="card-link">Abonnez-vous →</a>
</div>

</div>

</section>

<section id="remerciements">

## Remerciements

**Contributeurs**
- [Orpheus Lummis](https://www.orpheuslummis.info/) — Fondateur
- [Étienne Langlois](https://ca.linkedin.com/in/%C3%A9tienne-langlois-2a3119294/en) — Coordination et stratégie en sûreté de l'IA
- [Linda Linsefors](https://www.lesswrong.com/users/linda-linsefors) — Conseillère, événements et sûreté de l'IA
- [Arjun Yadav](https://www.arjunyadav.net/) — Soutien généraliste et événements
- [Manu García](https://www.linkedin.com/in/manu-garcía-communications-specialist) — Spécialiste en communications et coordination d'événements
- [Pascal Huynh](https://www.facebook.com/pozcal) — Design d'événements et d'interactions
- [Nicolas Grenier](https://en.wikipedia.org/wiki/Nicolas_Grenier_(artist)) — Conseiller, worlding
- [Richard Mallah](https://www.linkedin.com/in/richardmallah/) — Conseiller, série AI Safety Unconference
- [Mario Gibney](https://www.linkedin.com/in/mario-gibney-08bb7b45/) — Conseiller, développement du domaine de la sûreté de l'IA
- [Diego Jiménez](https://co.linkedin.com/in/diegomauriciojimenez/en) — Stratégie IA et opérations événementielles
- [Vaughn DiMarco](https://va.ug.hn/) — Conseiller, série AI Safety Unconference
- [David Krueger](https://davidscottkrueger.com/) — Coorganisateur, série AI Safety Unconference

**Bailleurs de fonds et commanditaires**
- [Long‑Term Future Fund (EA Funds)](https://funds.effectivealtruism.org/funds/far-future)
- [Survival and Flourishing Fund](https://survivalandflourishing.fund/)
- [Effective Altruism Foundation](https://ea-foundation.org/)
- [Future of Life Institute](https://futureoflife.org/)

</section>

<section id="contact">

## Contact

<p>Nous aimerions avoir de vos nouvelles. Contactez-nous pour discuter de collaborations, poser des questions ou explorer des opportunités de travailler ensemble sur des initiatives en sûreté de l'IA.</p>

<div class="cta-group">
  <a href="mailto:team@horizonomega.org" class="btn btn-primary">Contactez-nous</a>
  <a href="https://cal.com/horizonomega" class="btn btn-secondary">Planifiez un appel</a>
</div>

</section>
