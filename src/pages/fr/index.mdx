---
layout: ../../layouts/Layout.astro
title: HΩ
---

<div class="hero">

# HΩ

<div class="purpose-statement">Le progrès de la sûreté de l'IA <span class="purpose-detail">par la collaboration, la recherche et l'éducation.</span></div>

<div class="cta-group">
  <a href="#impliquez-vous" class="btn">Impliquez-vous</a>
</div>

</div>

<section id="ce-quon-fait">

## Ce que nous faisons

<div class="editorial-grid">

<div class="editorial-item">
<span class="editorial-meta">Depuis 2024 · 275+ abonnés</span>

**[Séminaires IA garantie sécuritaire](https://luma.com/guaranteedsafeaiseminars)** Séminaires techniques mensuels sur les approches quantitatives et garanties de sûreté. Nous recevons des chercheurs de premier plan dont Yoshua Bengio, Steve Omohundro, Tan Zhi Xuan et Jobst Heitzig.

</div>

<div class="editorial-item">
<span class="editorial-meta">Depuis 2025 · 1600+ membres</span>

**[Sûreté de l'IA à Montréal](https://aisafetymontreal.org)** Hub local qui sert la communauté montréalaise en sûreté, éthique et gouvernance de l'IA. Meetups, sessions de cotravail, ateliers ciblés, accompagnement et collaborations.

</div>

<div class="editorial-item">
<span class="editorial-meta">Depuis 2025</span>

**[Coordination canadienne en sûreté de l'IA](mailto:team@horizonomega.org?subject=Traité%20canadien%20sûreté%20IA)** Groupe de coordination entre organisations canadiennes et réseau travaillant vers la sûreté de l'IA.

</div>

<div class="editorial-item">
<span class="editorial-meta">Depuis 2018 · 400+ chercheurs</span>

**[AI Safety Unconference](https://www.aisafetyunconference.org/)** Événements dirigés par les participants avec présentations, sessions, discussions modérées et rencontres individuelles. Nous avons organisé AI Safety Unconference @ NeurIPS (2018–2022), Virtual AI Safety Unconference (2024), et une édition hybride prévue pour 2026.

</div>

<div class="editorial-item">
<span class="editorial-meta">Depuis 2024</span>

**[Horizon Events](https://www.horizonevents.info/)** Nous organisons plusieurs séries d'événements mondiaux en sûreté de l'IA. Nous soutenons l'écosystème élargi d'événements et d'initiatives en sûreté de l'IA.

</div>

</div>

</section>

<section id="bilan">

## Bilan

Nous avons mobilisé des milliers de participants à travers nos événements et canaux depuis 2018. Nous bâtissons une communauté qui compte maintenant 1600+ membres à Montréal et facilité la collaboration inter-organisationnelle à l'échelle mondiale.

<div class="editorial-grid">

<div class="editorial-item">
<span class="editorial-meta">2018–2022</span>

**[AI Safety Unconference @ NeurIPS](https://www.horizonevents.info/events/ai-safety-unconference)** Années de rassemblements dirigés par les participants avec présentations éclair, discussions modérées et sessions individuelles. 60+ participants par événement provenant d'organismes de premier plan dont Anthropic, DeepMind, OpenAI, Mila, MIRI, MIT, Stanford, Oxford, Cambridge et plus.

</div>

<div class="editorial-item">
<span class="editorial-meta">2024–présent</span>

**[Séminaires IA garantie sécuritaire](https://luma.com/guaranteedsafeaiseminars)** Présentations techniques mensuelles avec 15–30 participants en direct par session, et 600+ inscriptions totales annuellement. Conférenciers invités : Yoshua Bengio, Steve Omohundro, Tan Zhi Xuan et Jobst Heitzig.

</div>

<div class="editorial-item">
<span class="editorial-meta">2025–présent</span>

**[Communauté sûreté de l'IA de Montréal](https://aisafetymontreal.org/)** Nous avons bâti l'écosystème local par des meetups, des sessions de cotravail, des ateliers ciblés et la coanimation du groupe de lecture en sûreté de l'IA de Mila (sessions bihebdomadaires avec 10–20 chercheurs). Nous servons des membres en sûreté, éthique et gouvernance de l'IA.

</div>

<div class="editorial-item">
<span class="editorial-meta">2022, 2025</span>

**[Atelier Limits to Control](http://limitstocontrol.org)** Coorganisation d'un atelier centré sur les difficultés ou impossibilités de contrôler des systèmes d'IA avancés. L'édition 2025 a réuni des chercheurs pour cartographier le territoire des limites de contrôle de l'IA et a produit un énoncé collectif.

</div>

<div class="editorial-item">
<span class="editorial-meta">2023–présent</span>

**[Infolettre AI Safety Events & Training](https://aisafetyeventsandtraining.substack.com/)** Nous avons fondé son Substack en 2023, contribuant à la curation d'événements et à la croissance de la communauté.

</div>

</div>

<div class="testimonials">

### Ce que disent les participants

> « Utile pour suivre les avancées et lancer des collaborations. » — **Haydn Belfield**, Google DeepMind

> « Très utile pour rencontrer et discuter avec les chercheurs en sûreté de l'IA à NeurIPS. » — **Esben Kran**, Apart Research

> « Une excellente façon de rencontrer les meilleures personnes du domaine et propulser des idées audacieuses. » — **Stuart Armstrong**, Aligned AI

> « Les petits groupes de discussion m'ont exposé à de nouvelles perspectives. » — **Adam Gleave**, FAR.AI

</div>

</section>

<section id="impliquez-vous">

## Impliquez-vous

<div class="editorial-grid">

<div class="editorial-item">

**[Bénévolat](mailto:team@horizonomega.org?subject=Bénévolat)** Nous accueillons des bénévoles pour les opérations des séminaires, les synthèses de recherche, la sollicitation de conférenciers et le montage vidéo. Formation et gabarits fournis.

</div>

<div class="editorial-item">

**[Partenariat](mailto:team@horizonomega.org?subject=Partenariat)** Nous collaborons avec des universités, des labos, des ONG et des organismes de normalisation pour coorganiser des sessions, partager des conférenciers et bâtir des projets pilotes.

</div>

<div class="editorial-item">

**[Soutien](mailto:team@horizonomega.org?subject=Soutien)** Votre soutien nous permet d'élargir nos collaborations, événements et recherches. Commandites, subventions et contributions en nature (hébergement de lieu, sous-titrage, montage, design) bienvenues.

</div>

<div class="editorial-item">

**[Conseillers](mailto:team@horizonomega.org?subject=Conseillers)** Nous cherchons des conseillers séniors en vérification, évaluations et gouvernance. Politique de conflit d'intérêts applicable.

</div>

<div class="editorial-item">

**[Suivi](https://horizonomega.substack.com/)** Restez au courant des événements en sûreté de l'IA, des opportunités de formation et de nos dernières initiatives. Abonnez-vous à notre infolettre et suivez-nous sur les réseaux sociaux.

</div>

</div>

</section>

<section id="remerciements">

## Remerciements

### Contributeurs

<div class="acknowledgements-table">

| | |
|---|---|
| [Orpheus Lummis](https://www.orpheuslummis.info/) | Fondateur |
| [Étienne Langlois](https://ca.linkedin.com/in/%C3%A9tienne-langlois-2a3119294/en) | Coordination et stratégie en sûreté de l'IA |
| [Linda Linsefors](https://www.lesswrong.com/users/linda-linsefors) | Conseillère, événements et sûreté de l'IA |
| [Arjun Yadav](https://www.arjunyadav.net/) | Soutien généraliste et événements |
| [Manu García](https://www.linkedin.com/in/manu-garcía-communications-specialist) | Spécialiste en communications et coordination d'événements |
| [Pascal Huynh](https://www.facebook.com/pozcal) | Design d'événements et d'interactions |
| [Nicolas Grenier](https://en.wikipedia.org/wiki/Nicolas_Grenier_(artist)) | Conseiller, worlding |
| [Richard Mallah](https://www.linkedin.com/in/richardmallah/) | Conseiller, série AI Safety Unconference |
| [Mario Gibney](https://www.linkedin.com/in/mario-gibney-08bb7b45/) | Conseiller, développement du domaine de la sûreté de l'IA |
| [Diego Jiménez](https://co.linkedin.com/in/diegomauriciojimenez/en) | Stratégie IA et opérations événementielles |
| [Vaughn DiMarco](https://va.ug.hn/) | Conseiller, série AI Safety Unconference |
| [David Krueger](https://davidscottkrueger.com/) | Coorganisateur, série AI Safety Unconference |

</div>

### Bailleurs de fonds et commanditaires

<div class="acknowledgements-table">

| |
|---|
| [Long‑Term Future Fund (EA Funds)](https://funds.effectivealtruism.org/funds/far-future) |
| [Survival and Flourishing Fund](https://survivalandflourishing.fund/) |
| [Effective Altruism Foundation](https://ea-foundation.org/) |
| [Future of Life Institute](https://futureoflife.org/) |

</div>

</section>

<section id="contact">

## Contact

Nous aimerions avoir de vos nouvelles. Contactez-nous pour discuter de collaborations, poser des questions ou explorer des opportunités de travailler ensemble sur des initiatives en sûreté de l'IA.

<a href="mailto:team@horizonomega.org" class="btn">Contactez-nous</a>
<a href="https://cal.com/horizonomega" class="btn">Planifiez un appel</a>

</section>
